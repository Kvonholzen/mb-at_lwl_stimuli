filter(stimulus_novelty == "familiar") %>%
#window of analysis
filter(t_norm >= t_min, t_norm <= t_max) %>%
#bin ages (can adjust size of age bins here)
mutate(age_binned = cut(age, seq(12,60,age_bin_size))) %>%
rename(target_label = english_stimulus_label) %>%
group_by(dataset_name,subject_id, trial_id, target_label,
age, age_binned) %>%
summarise(prop_target_looking = sum(aoi == "target", na.rm = TRUE) /
(sum(aoi == "target", na.rm=TRUE) +
sum(aoi=="distractor", na.rm=TRUE)),
prop_missing = mean(aoi %in% c("missing","other"), na.rm = TRUE)) %>%
#remove trials with insufficient looking to target or distractor
filter(prop_missing<=max_prop_missing)
#### PARAMETERS TO SET ####
#critical window dimensions roughly consistent with e.g., Swingley & Aslin, 2002
t_min <- 300
t_max <- 2000
#proportion missing trials threshold (any trial in which over half of the critical window missing is looking data is excluded )
max_prop_missing <- 0.5
#age bin size (number of months per bin)
age_bin_size <- 6
by_trial_means <- aoi_data_joined %>%
#restrict to english datasets (this is just because there are so few non-English datasets atm)
filter(native_language == "eng") %>%
#restrict age range
filter(age > 12, age <= 60) %>%
# familiar target items only %>%
filter(stimulus_novelty == "familiar") %>%
#window of analysis
filter(t_norm >= t_min, t_norm <= t_max) %>%
#bin ages (can adjust size of age bins here)
mutate(age_binned = cut(age, seq(12,60,age_bin_size))) %>%
rename(target_label = english_stimulus_label) %>%
group_by(dataset_name,subject_id, trial_id, target_label,
age, age_binned) %>%
summarise(prop_target_looking = sum(aoi == "target", na.rm = TRUE) /
(sum(aoi == "target", na.rm=TRUE) +
sum(aoi=="distractor", na.rm=TRUE)),
prop_missing = mean(aoi %in% c("missing","other"), na.rm = TRUE)) %>%
#remove trials with insufficient looking to target or distractor
filter(prop_missing<=max_prop_missing)
View(by_trial_means)
by_subj_item_means <- by_trial_means %>%
group_by(dataset_name,subject_id, target_label,
age, age_binned) %>%
summarise(
trial_num=n(),
avg_target_looking = mean(prop_target_looking,na.rm=TRUE)
)
View(by_subj_item_means)
by_item_means <- by_subj_item_means %>%
group_by(dataset_name, target_label,age_binned) %>%
summarise(
subj_n=n(),
target_looking = mean(avg_target_looking,na.rm=TRUE)
)
view(by_item_means)
# here I change Martin's script to average over dataset_name as well
by_item_means <- by_subj_item_means %>%
#group_by(dataset_name, target_label,age_binned) %>%
group_by(target_label,age_binned) %>%
summarise(
subj_n=n(),
target_looking = mean(avg_target_looking,na.rm=TRUE)
)
View(by_item_means)
word_list <- c("dog",
"doggy",
"eat",
"sit",
"sleep",
"drink (action)",
"hug",
"kiss",
"point",
"stand",
"play",
"apple",
"baby",
"ball",
"banana",
"bird",
"boat",
"book",
"bottle",
"car",
"carrots",
"bat",
"cookie",
"cow",
"cup",
"duck",
"fish (animal)",
"foot",
"frog",
"hand",
"horse",
"juice",
"lion",
"milk",
"monkey",
"shoe",
"sock",
"spoon",
"train",
"truck")
word_list <- as.data.frame(word_list)
word_list$order <- rownames(word_list)
dat <- merge(by_item_means, word_list, by.x = "target_label", by.y = "word_list", all.y = T)
View(dat)
unique(dat$age_binned)
dat$needed_bins <- ifelse(dat$age_binned == "(12,18]", "(12,18)",
ifelse(dat$age_binned == "(18,24]", "(18,24)", "(24,60)"))
# here I change Martin's script to average over dataset_name as well
by_item_means <- by_subj_item_means %>%
#group_by(dataset_name, target_label,age_binned) %>%
group_by(target_label,needed_bins) %>%
summarise(
subj_n=n(),
target_looking = mean(avg_target_looking,na.rm=TRUE)
)
by_subj_item_means$needed_bins <- ifelse(by_subj_item_means$age_binned == "(12,18]", "(12,18)",
ifelse(by_subj_item_means$age_binned == "(18,24]", "(18,24)", "(24,60)"))
# here I change Martin's script to average over dataset_name as well
by_item_means <- by_subj_item_means %>%
#group_by(dataset_name, target_label,age_binned) %>%
group_by(target_label,needed_bins) %>%
summarise(
subj_n=n(),
target_looking = mean(avg_target_looking,na.rm=TRUE)
)
View(by_item_means)
# here starts Katie's mess
word_list <- c("dog",
"doggy",
"eat",
"sit",
"sleep",
"drink (action)",
"hug",
"kiss",
"point",
"stand",
"play",
"apple",
"baby",
"ball",
"banana",
"bird",
"boat",
"book",
"bottle",
"car",
"carrots",
"bat",
"cookie",
"cow",
"cup",
"duck",
"fish (animal)",
"foot",
"frog",
"hand",
"horse",
"juice",
"lion",
"milk",
"monkey",
"shoe",
"sock",
"spoon",
"train",
"truck")
word_list <- as.data.frame(word_list)
word_list$order <- rownames(word_list)
dat <- merge(by_item_means, word_list, by.x = "target_label", by.y = "word_list", all.y = T)
View(dat)
dat <- dat %>%
pivot_wider(names_from = needed_bins, values_from = target_looking)
View(dat)
# here I change Martin's script to average over dataset_name as well
by_item_means <- by_subj_item_means %>%
#group_by(dataset_name, target_label,age_binned) %>%
group_by(target_label,needed_bins) %>%
summarise(
target_looking = mean(avg_target_looking,na.rm=TRUE)
)
word_list <- c("dog",
"doggy",
"eat",
"sit",
"sleep",
"drink (action)",
"hug",
"kiss",
"point",
"stand",
"play",
"apple",
"baby",
"ball",
"banana",
"bird",
"boat",
"book",
"bottle",
"car",
"carrots",
"bat",
"cookie",
"cow",
"cup",
"duck",
"fish (animal)",
"foot",
"frog",
"hand",
"horse",
"juice",
"lion",
"milk",
"monkey",
"shoe",
"sock",
"spoon",
"train",
"truck")
word_list <- as.data.frame(word_list)
word_list$order <- rownames(word_list)
dat <- merge(by_item_means, word_list, by.x = "target_label", by.y = "word_list", all.y = T)
dat <- dat %>%
pivot_wider(names_from = needed_bins, values_from = target_looking)
View(dat)
str(dat)
dat <- merge(by_item_means, word_list, by.x = "target_label", by.y = "word_list", all.y = T)
dat <- dat %>%
pivot_wider(names_from = needed_bins, values_from = target_looking)
dat <- dat[,c("order", "target_label", "(12,18)", "(18,24)", "(24,60)")]
dat$order <- as.numeric(dat$order)
View(dat)
# load the library
library(childesr)
install.packages("childesr")
# load the library
library(childesr)
library(dplyr)
# check how language is coded
d_transcripts <- get_transcripts()
View(d_transcripts)
unique(d_transcripts$language)
# get English, Northern America transcripts
d_eng_na <- get_transcripts(collection = "Eng-NA")
View(d_eng_na)
d_age_range <- get_participants(collection = "Eng-NA", age = c(24, 36))
View(d_age_range)
d_age_range <- get_participants(collection = "Eng-NA", age = c(12, 36))
View(d_age_range)
View(d_eng_na)
?get_tokens
d_prod <- get_tokens(collection = "Eng-NA",
age = c(12, 36),
role = "target_child",
token = c("dog", "ball"))
View(d_prod)
word_list <- c("dog",
"doggy",
"eat",
"sit",
"sleep",
"drink (action)",
"hug",
"kiss",
"point",
"stand",
"play",
"apple",
"baby",
"ball",
"banana",
"bird",
"boat",
"book",
"bottle",
"car",
"carrots",
"bat",
"cookie",
"cow",
"cup",
"duck",
"fish (animal)",
"foot",
"frog",
"hand",
"horse",
"juice",
"lion",
"milk",
"monkey",
"shoe",
"sock",
"spoon",
"train",
"truck")
d_prod <- get_tokens(collection = "Eng-NA",
age = c(12, 36),
role = "target_child",
token = word_list)
View(d_prod)
View(d_prod)
prod_sum <- d_prod %>%
group_by(gloss, corpus_name, target_child_age, target_child_id)
View(prod_sum)
prod_sum <- d_prod %>%
group_by(gloss, corpus_name, target_child_age, target_child_id)%>%
summarise(total_utt = n())
View(prod_sum)
prod_sum <- d_prod %>%
group_by(gloss, corpus_name, target_child_age, target_child_name)%>%
summarise(total_utt = n())
prod_sum <- d_prod %>%
group_by(gloss, corpus_name, target_child_age, target_child_name)%>%
summarise(word_utt = n())
speaker_stats <- get_speaker_statistics(collection = "Eng-NA",
age = c(12, 36),
role = "target_child",
token = word_list)
speaker_stats <- get_speaker_statistics(collection = "Eng-NA",
age = c(12, 36),
role = "target_child")
View(speaker_stats)
View(d_prod)
speaker_stats <- speaker_stats[,c("speaker_id", "target_child_age", "num_utterances", "num_tokens")]
prod_sum <- d_prod %>%
group_by(gloss, corpus_name, target_child_age, speaker_id)%>%
summarise(word_utt = n())
speaker_stats <- get_speaker_statistics(collection = "Eng-NA",
age = c(12, 36),
role = "target_child")
speaker_stats <- speaker_stats[,c("speaker_id", "target_child_age", "num_utterances", "num_tokens")]
prod_stats <- merge(prod_sum, speaker_stats, by = c("speaker_id", "target_child_age"))
View(prod_stats)
prod_stats$token_ratio <- prod_stats$word_utt/prod_stats$num_tokens
sp <- prod_stats %>%
group_by(gloss)%>%
summarise(avg_token_ratio = mean(token_ratio, na.rm = T))
View(sp)
prod_stats$gloss <- tolower(prod_stats$gloss)
sp <- prod_stats %>%
group_by(gloss)%>%
summarise(avg_token_ratio = mean(token_ratio, na.rm = T))
View(sp)
mean(0)
mean(c(1,NA))
# prod_stats gives wierd Inf in some token_ratio rows
prod_stats < subset(prod_stats, token_ratio != Inf)
prod_stats <- merge(prod_sum, speaker_stats, by = c("speaker_id", "target_child_age"))
prod_stats$token_ratio <- prod_stats$word_utt/prod_stats$num_tokens
prod_stats$gloss <- tolower(prod_stats$gloss)
# num_tokens is 0 for some children
# remove them, can't have those 0's!
prod_stats < subset(prod_stats, num_tokens != 0)
prod_stats <- merge(prod_sum, speaker_stats, by = c("speaker_id", "target_child_age"))
prod_stats < subset(prod_stats, num_tokens != 0)
prod_stats <- merge(prod_sum, speaker_stats, by = c("speaker_id", "target_child_age"))
prod_stats <- subset(prod_stats, num_tokens != 0)
prod_stats$token_ratio <- prod_stats$word_utt/prod_stats$num_tokens
prod_stats$gloss <- tolower(prod_stats$gloss)
sp <- prod_stats %>%
group_by(gloss)%>%
summarise(avg_token_ratio = mean(token_ratio, na.rm = T))
View(sp)
word_list <- as.data.frame(word_list)
word_list$order <- rownames(word_list)
dat <- merge(sp, word_list, by.x = "gloss", by.y = "word_list", all.y = T)
View(dat)
dat$order <- as.numeric(dat$order)
# load the library
library(childesr)
library(dplyr)
word_list <- c("dog",
"doggy",
"eat",
"sit",
"sleep",
"drink",
"hug",
"kiss",
"point",
"stand",
"play",
"apple",
"baby",
"ball",
"banana",
"bird",
"boat",
"book",
"bottle",
"car",
"carrots",
"bat",
"cookie",
"cow",
"cup",
"duck",
"fish",
"foot",
"frog",
"hand",
"horse",
"juice",
"lion",
"milk",
"monkey",
"shoe",
"sock",
"spoon",
"train",
"truck")
d_prod <- get_tokens(collection = "Eng-NA",
age = c(12, 36),
role = "target_child",
token = word_list)
# get number of utterances per child, per word
prod_sum <- d_prod %>%
group_by(gloss, corpus_name, target_child_age, speaker_id)%>%
summarise(word_utt = n())
speaker_stats <- get_speaker_statistics(collection = "Eng-NA",
age = c(12, 36),
role = "target_child")
speaker_stats <- speaker_stats[,c("speaker_id", "target_child_age", "num_utterances", "num_tokens")]
prod_stats <- merge(prod_sum, speaker_stats, by = c("speaker_id", "target_child_age"))
# num_tokens is 0 for some children
# remove them, can't have those 0's!
prod_stats <- subset(prod_stats, num_tokens != 0)
prod_stats$token_ratio <- prod_stats$word_utt/prod_stats$num_tokens
prod_stats$gloss <- tolower(prod_stats$gloss)
sp <- prod_stats %>%
group_by(gloss)%>%
summarise(avg_token_ratio = mean(token_ratio, na.rm = T))
dat <- dat[,c("order", "gloss", "avg_token_ratio")]
# load the library
library(childesr)
library(dplyr)
word_list <- c("dog",
"doggy",
"eat",
"sit",
"sleep",
"drink",
"hug",
"kiss",
"point",
"stand",
"play",
"apple",
"baby",
"ball",
"banana",
"bird",
"boat",
"book",
"bottle",
"car",
"carrots",
"bat",
"cookie",
"cow",
"cup",
"duck",
"fish",
"foot",
"frog",
"hand",
"horse",
"juice",
"lion",
"milk",
"monkey",
"shoe",
"sock",
"spoon",
"train",
"truck")
d_prod <- get_tokens(collection = "Eng-NA",
age = c(12, 36),
role = "target_child",
token = word_list)
# get number of utterances per child, per word
prod_sum <- d_prod %>%
group_by(gloss, corpus_name, target_child_age, speaker_id)%>%
summarise(word_utt = n())
speaker_stats <- get_speaker_statistics(collection = "Eng-NA",
age = c(12, 36),
role = "target_child")
speaker_stats <- speaker_stats[,c("speaker_id", "target_child_age", "num_utterances", "num_tokens")]
prod_stats <- merge(prod_sum, speaker_stats, by = c("speaker_id", "target_child_age"))
# num_tokens is 0 for some children
# remove them, can't have those 0's!
prod_stats <- subset(prod_stats, num_tokens != 0)
prod_stats$token_ratio <- prod_stats$word_utt/prod_stats$num_tokens
prod_stats$gloss <- tolower(prod_stats$gloss)
sp <- prod_stats %>%
group_by(gloss)%>%
summarise(avg_token_ratio = mean(token_ratio, na.rm = T))
word_list <- as.data.frame(word_list)
word_list$order <- rownames(word_list)
dat <- merge(sp, word_list, by.x = "gloss", by.y = "word_list", all.y = T)
dat <- dat[,c("order", "gloss", "avg_token_ratio")]
dat$order <- as.numeric(dat$order)
